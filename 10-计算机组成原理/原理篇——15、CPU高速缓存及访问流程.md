#### CPU高速缓存及访问流程

##### 一、为什么需要高速缓存

按照摩尔定律，CPU 的访问速度每 18 个月便会翻一番，相当于每年增长 60%。内存的访问速度虽然也在不断增长，却远没有这么快，每年只增长 7% 左右。而这两个增长速度的差异，使得 CPU 性能和内存访问性能的差距不断拉大。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/4fc459f42a67d3949402865a998bf34b.png" alt="4fc459f42a67d3949402865a998bf34b" style="zoom: 50%;" />

因为 CPU 需要执行的指令、需要访问的数据，都在这个速度不到自己 1% 的内存里。为了弥补两者之间的性能差异，能真实地把 CPU 的性能提升用起来，而不是让它在那儿空转，现代 CPU 中引入了高速缓存。

从 CPU Cache 被加入到现有的 CPU 里开始，内存中的指令、数据，会被加载到 L1-L3 Cache 中，而不是直接由 CPU 访问内存去拿。在 95% 的情况下，CPU 都只需要访问 L1-L3 Cache，从里面读取指令和数据，而无需访问内存。

##### 二、Cache的数据结构和读取过程

**CPU 从内存中读取数据到 CPU Cache 的过程中，是一小块一小块来读取数据的，而不是按照单个数组元素来读取数据的。这样一小块一小块的数据，在 CPU Cache 里面，我们把它叫作 Cache Line（缓存块）**。

在我们日常使用的 Intel 服务器或者 PC 里，**Cache Line 的大小通常是 64 字节**。

现代 CPU 进行数据读取的时候，无论数据是否已经存储在 Cache 中，CPU 始终会首先访问 Cache。只有当 CPU 在 Cache 中找不到数据的时候，才会去访问内存，并将读取到的数据写入 Cache 之中。当时间局部性原理起作用后，这个最近刚刚被访问的数据，会很快再次被访问。这样，CPU 花在等待内存访问上的时间就大大变短了。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/3a6fcfd1155e03f4f2781dbb6ddaf6cc.png" alt="3a6fcfd1155e03f4f2781dbb6ddaf6cc" style="zoom: 50%;" />



**1、CPU 如何知道要访问的内存数据，存储在 Cache 的哪个位置呢？**

**直接映射 Cache（Direct Mapped Cache）**，直接映射 Cache 采用的策略，就是确保任何一个内存块的地址，始终映射到一个固定的 CPU Cache 地址（Cache Line）。而这个映射关系，通常用 mod 运算（求余运算）来实现。

比如，我们的主内存被分成 0～31 号这样 32 个块。我们一共有 8 个缓存块。用户想要访问第 21 号内存块。如果 21 号内存块内容在缓存块中的话，它一定在 5 号缓存块（21 mod 8 = 5）中。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/522eade51bbfad19fd25eb4f3ce80f22.png" alt="522eade51bbfad19fd25eb4f3ce80f22" style="zoom:50%;" />

实际计算中，有一个小小的技巧，通常我们会 **把缓存块的数量设置成 2 的 N 次方**。这样在计算取模的时候，可以直接取地址的低 N 位，也就是二进制里面的后几位。比如这里的 8 个缓存块，就是 2 的 3 次方。那么，在对 21 取模的时候，可以对 21 的 2 进制表示 10101 取地址的低三位，也就是 101，对应的 5，就是对应的缓存块地址。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/caadd2728b5cfcd2bd704103570f3a80.png" alt="caadd2728b5cfcd2bd704103570f3a80" style="zoom: 50%;" />

**2、怎么知道缓存里面的数据块的具体对应哪个内存块呢？**

在对应的缓存块中，我们会存储一个 **组标记（Tag）**。这个组标记会记录，当前缓存块内存储的数据对应的内存块，而 **缓存块本身的地址表示访问地址的低 N 位**。就像上面的例子，21 的低 3 位 101，缓存块本身的地址已经涵盖了对应的信息。对应的 **组标记**，**只需要记录** 21 **剩余的高** 2  **位的信息**，也就是 10 就可以了。

**3、怎么知道缓存块是否有效？**

**缓存块中除了数据、组标记信息** 之外，另一个是 **有效位（valid bit）**。就是用来标记，对应的缓存块中的数据是否是有效的，确保不是机器刚刚启动时候的空数据。如果有效位是 0，无论其中的组标记和 Cache Line 里的数据内容是什么，CPU 都不会管这些数据，而要直接访问内存，重新加载数据。

**4、CPU读取数据并不是读取一整个块**

CPU 在读取数据的时候，并不是要读取一整个 Block，而是读取一个他需要的数据片段。这样的数据，我们叫作 CPU 里的一个 **字（Word）**。具体是哪个字，就用这个字在整个 Block 里面的位置来决定。这个位置，我们叫作 **偏移量（Offset）**。

**一个内存的访问地址，最终包括高位代表的组标记、低位代表的索引，以及在对应的 Data Block 中定位对应字的位置偏移量。**

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/1313fe1e4eb3b5c949284c8b215af8d4.png" alt="1313fe1e4eb3b5c949284c8b215af8d4" style="zoom: 67%;" />

****

**内存地址对应到 Cache 里的数据结构，则多了一个有效位和对应的数据，由 “索引 + 有效位  + 组标记 + 数据”组成。**

**5、访问流程**

如果内存中的数据已经在 CPU Cache 里了，那一个内存地址的访问，就会经历这样 4 个步骤：

（1）根据内存地址的低位，计算在 Cache 中的索引；

（2）判断有效位，确认 Cache 中的数据是有效的；

（3）对比内存访问地址的高位，和 Cache 中的组标记，确认 Cache 中的数据就是我们要访问的内存数据，从 Cache Line 中读取到对应的数据块（Data Block）；

（4）根据内存地址的 Offset 位，从 Data Block 中，读取希望读取到的字。

如果在 2、3 这两个步骤中，CPU 发现，Cache 中的数据并不是要访问的内存地址的数据，那 CPU 就会访问内存，并把对应的 Block Data 更新到 Cache Line 中，同时更新对应的有效位和组标记的数据。





除了直接映射 Cache 之外，我们常见的缓存放置策略还有全相连 Cache（Fully Associative Cache）、组相连 Cache（Set Associative Cache）。现代 CPU 已经很少使用直接映射 Cache 了，通常用的是组相连 Cache（set associative cache），想要了解组相连 Cache，你可以阅读《计算机组成与设计：硬件 / 软件接口》的 5.4.1 小节。