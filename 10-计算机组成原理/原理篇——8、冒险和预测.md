#### 冒险和预测

流水线设计需要解决的三大冒险，分别是 **结构冒险（Structural Hazard）、数据冒险（Data Hazard）以及控制冒险（Control Hazard）**。

##### 一、结构冒险和解决方案

###### 1、结构冒险

结构冒险，本质上是一个硬件层面的资源竞争问题，也就是一个硬件电路层面的问题。

5级流水线的示意图：

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/c2a4c0340cb835350ea954cdc520704e.jpeg" alt="c2a4c0340cb835350ea954cdc520704e" style="zoom:33%;" />

在第 1 条指令执行到访存（MEM）阶段的时候，流水线里的第 4 条指令，在执行取指令（Fetch）的操作。访存和取指令，都要进行内存数据的读取。我们的内存，只有一个地址译码器的作为地址输入，那就只能在一个时钟周期里面读取一条数据，没办法同时执行第 1 条指令的读取内存数据和第 4 条指令的读取指令代码。

###### 2、结构冒险解决方案

（1）**增加资源**

**直观的解决方案就是把我们的内存分成两部分**，让它们各有各的地址译码器。这两部分分别是存放指令的程序内存和存放数据的数据内存。

现代的 CPU 虽然没有在内存层面进行对应的拆分，却在 CPU 内部的高速缓存部分进行了区分，把高速缓存分成了 **指令缓存（Instruction Cache）**和 **数据缓存（Data Cache）**两部分。内存的访问速度远比 CPU 的速度要慢，所以现代的 CPU 并不会直接读取主内存。它会从主内存把指令和数据加载到高速缓存中，这样后续的访问都是访问高速缓存。而指令缓存和数据缓存的拆分，使得我们的 CPU 在进行数据访问和取指令的时候，不会再发生资源冲突的问题了。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/e7508cb409d398380753b292b6df8391.jpeg" alt="e7508cb409d398380753b292b6df8391" style="zoom:33%;" />

（2）**NOP操作和指令对齐**

有些指令没有对应的流水线阶段，但是我们并不能跳过对应的阶段直接执行下一阶段。不然，如果我们先后执行一条 LOAD 指令和一条 ADD 指令，就会发生 LOAD 指令的 WB 阶段和 ADD 指令的 WB 阶段，在同一个时钟周期发生。这样，相当于触发了一个结构冒险事件，产生了资源竞争。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/b66ea9ca3300c7f71e91aaa6b6428fd4.jpg" alt="b66ea9ca3300c7f71e91aaa6b6428fd4" style="zoom:33%;" />

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/9e62ab3b42e445d65accf0549badf45f.jpeg" alt="9e62ab3b42e445d65accf0549badf45f" style="zoom:33%;" />

所以，在实践当中，各个指令不需要的阶段，并不会直接跳过，而是会运行一次 NOP 操作。通过插入一个 NOP 操作，我们可以使后一条指令的每一个 Stage，一定不和前一条指令的同 Stage 在一个时钟周期执行。这样，就不会发生先后两个指令，在同一时钟周期竞争相同的资源，产生结构冒险了。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/c16643d83dd534d3d97d0d7ad8e30d42.jpg" alt="c16643d83dd534d3d97d0d7ad8e30d42" style="zoom:33%;" />

##### 二、数据冒险和解决方案

###### 1、数据冒险

数据冒险，其实就是同时在执行的多个指令之间，有数据依赖的情况。这些数据依赖，我们可以分成三大类，分别是 **先写后读（Read After Write，RAW）**、**先读后写（Write After Read，WAR）**和 **写后再写（Write After Write，WAW）**。

**（1）先写后读（Read After Write）**

```
int main() {
  int a = 1;
  int b = 2;
  a = b + a;
  b = a + b;
}

//汇编
int main() {
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
  int a = 1;
   4:   c7 45 fc 01 00 00 00    mov    DWORD PTR [rbp-0x4],0x1
  int b = 2;
   b:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
  a = a + 2;
  12:   83 45 fc 02             add    DWORD PTR [rbp-0x4],0x2
  b = a + 3;
  16:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  19:   83 c0 03                add    eax,0x3
  1c:   89 45 f8                mov    DWORD PTR [rbp-0x8],eax
}
  1f:   5d                      pop    rbp
  20:   c3                      ret        
```

我们需要保证，在内存地址为 16 的指令读取 rbp-0x4 里面的值之前，内存地址 12 的指令写入到 rbp-0x4 的操作必须完成。这就是先写后读所面临的数据依赖。如果这个顺序保证不了，我们的程序就会出错。这个先写后读的依赖关系，我们一般被称之为 **数据依赖**，也就是 Data Dependency。

**（2）先读后写（Write After Read）**

```
int main() {
  int a = 1;
  int b = 2;
  a = b + a;
  b = a + b;
}
//汇编
int main() {
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
   int a = 1;
   4:   c7 45 fc 01 00 00 00    mov    DWORD PTR [rbp-0x4],0x1
   int b = 2;
   b:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
   a = b + a;
  12:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  15:   01 45 fc                add    DWORD PTR [rbp-0x4],eax
   b = a + b;
  18:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  1b:   01 45 f8                add    DWORD PTR [rbp-0x8],eax
}
  1e:   5d                      pop    rbp
  1f:   c3                      ret       
```

在内存地址为 15 的汇编指令里，我们要把 eax 寄存器里面的值读出来，再加到 rbp-0x4 的内存地址里。接着在内存地址为 18 的汇编指令里，我们要再写入更新 eax 寄存器里面。如果我们在内存地址 18 的 eax 的写入先完成了，在内存地址为 15 的代码里面取出 eax 才发生，我们的程序计算就会出错。这里，我们同样要保障对于 eax 的先读后写的操作顺序。这个先读后写的依赖，一般被叫作 **反依赖**，也就是 Anti-Dependency。 

**（3）写后再写（Write After Write）**

```
int main() {
  int a = 1;
  a = 2;
}
//汇编
int main() {
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
  int a = 1;
   4:   c7 45 fc 01 00 00 00    mov    DWORD PTR [rbp-0x4],0x1
  a = 2;
   b:   c7 45 fc 02 00 00 00    mov    DWORD PTR [rbp-0x4],0x2
}
```

我们也需要保障内存地址 4 的指令的写入，在内存地址 b 的指令的写入之前完成。这个写后再写的依赖，一般被叫作 **输出依赖**，也就是 Output Dependency。

###### 2、数据冒险的解决方案

（1）**流水线停顿（Pipeline Stall）**，或者叫 **流水线冒泡（Pipeline Bubbling）**

水线停顿的办法很容易理解。如果我们发现了后面执行的指令，会对前面执行的指令有数据层面的依赖关系，那最简单的办法就是“再等等”。我们在进行指令译码的时候，会拿到对应指令所需要访问的寄存器和内存地址。所以，在这个时候，我们能够判断出来，这个指令是否会触发数据冒险。如果会触发数据冒险，我们就可以决定，让整个流水线停顿一个或者多个周期。其实，我们并没有办法真的停顿下来。流水线的每一个操作步骤必须要干点儿事情。所以，在实践过程中，我们并不是让流水线停下来，而是在执行后面的操作步骤前面，插入一个 NOP 操作，也就是执行一个其实什么都不干的操作。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/0d762f2ce532d87cfe69c7b167af9c2a.jpeg" alt="0d762f2ce532d87cfe69c7b167af9c2a" style="zoom:33%;" />

（2）**操作数前推**

```
add $t0, $s2,$s1
add $s2, $s1,$t0
//第一条指令，把 s1 和 s2 寄存器里面的数据相加，存入到 t0 这个寄存器里面。
//第二条指令，把 s1 和 t0 寄存器里面的数据相加，存入到 s2 这个寄存器里面。
```

因为后一条的 add 指令，依赖寄存器 t0 里的值。而 t0 里面的值，又来自于前一条指令的计算结果。所以后一条指令，需要等待前一条指令的数据写回阶段完成之后，才能执行。于是，我们就不得不通过流水线停顿来解决这个冒险问题。我们要在第二条指令的译码阶段之后，插入对应的 NOP 指令，直到前一天指令的数据写回完成之后，才能继续执行。这样的方案，也浪费了两个时钟周期。我们的第 2 条指令，其实就是多花了 2 个时钟周期，运行了两次空转的 NOP 操作。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/94dda2330b07c08530540ae11838c569.jpeg" alt="94dda2330b07c08530540ae11838c569" style="zoom:33%;" />

其实第二条指令的执行，未必要等待第一条指令写回完成，才能进行。我们完全可以在第一条指令的执行阶段完成之后，直接将结果数据传输给到下一条指令的 ALU。然后，下一条指令不需要再插入两个 NOP 阶段，就可以继续正常走到执行阶段。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/dceadd35c334974d8270052b37d48c27.jpeg" alt="dceadd35c334974d8270052b37d48c27" style="zoom:33%;" />

这样的解决方案，我们就叫作 **操作数前推**（Operand Forwarding），或者 **操作数旁路**（Operand Bypassing）。在 CPU 的硬件里面，需要再单独拉一根信号传输的线路出来，使得 ALU 的计算结果，能够重新回到 ALU 的输入里来。这样的一条线路，就是我们的“旁路”。它越过（Bypass）了写入寄存器，再从寄存器读出的过程，也为我们节省了 2 个时钟周期。

**操作数前推的解决方案不但可以单独使用，还可以和流水线冒泡一起使用**。有的时候，虽然我们可以把操作数转发到下一条指令，但是下一条指令仍然需要停顿一个时钟周期。

比如说，我们先去执行一条 LOAD 指令，再去执行 ADD 指令。LOAD 指令在访存阶段才能把数据读取出来，所以下一条指令的执行阶段，需要在访存阶段完成之后，才能进行。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/49f3a9b1ae2972ac5c6cfca7731bf12d.jpeg" alt="49f3a9b1ae2972ac5c6cfca7731bf12d" style="zoom:33%;" />

**（3）乱序执行（指令重排序？）**

无论是流水线停顿，还是操作数前推，归根到底，只要前面指令的特定阶段还没有执行完成，后面的指令就会被“阻塞”住。但是这个“阻塞”很多时候是没有必要的。因为尽管你的代码生成的指令是顺序的，但是如果后面的指令不需要依赖前面指令的执行结果，完全可以不必等待前面的指令运算完成。

```
a = b + c
d = a * e
x = y * z
```

计算里面的 x ，却要等待 a 和 d 都计算完成，实在没啥必要。所以我们完全可以在 d 的计算等待 a 的计算的过程中，先把 x 的结果给算出来。在流水线里，后面的指令不依赖前面的指令，那就不用等待前面的指令执行，它完全可以先执行。这样的解决方案，在计算机组成里面，被称为 **乱序执行（Out-of-Order Execution，OoOE）**。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/37ba6c453e530660cecbbfcf56a3ecef.jpeg" alt="37ba6c453e530660cecbbfcf56a3ecef" style="zoom:33%;" />

**指令乱序执行原理**：

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/153f8d5e4a4363399133e1d7d9052804.jpeg" alt="153f8d5e4a4363399133e1d7d9052804" style="zoom:33%;" />

1. 在取指令和指令译码的时候，乱序执行的 CPU 和其他使用流水线架构的 CPU 是一样的。它会一级一级顺序地进行取指令和指令译码的工作。

2. 在指令译码完成之后，就不一样了。CPU 不会直接进行指令执行，而是进行一次指令分发，把指令发到一个叫作保留站（Reservation Stations）的地方。顾名思义，这个保留站，就像一个火车站一样。发送到车站的指令，就像是一列列的火车。

3. 这些指令不会立刻执行，而要等待它们所依赖的数据，传递给它们之后才会执行。这就好像一列列的火车都要等到乘客来齐了才能出发。

4.  一旦指令依赖的数据来齐了，指令就可以交到后面的功能单元（Function Unit，FU），其实就是 ALU，去执行了。我们有很多功能单元可以并行运行，但是不同的功能单元能够支持执行的指令并不相同。就和我们的铁轨一样，有些从上海北上，可以到北京和哈尔滨；有些是南下的，可以到广州和深圳。

5. 指令执行的阶段完成之后，我们并不能立刻把结果写回到寄存器里面去，而是把结果再存放到一个叫作重排序缓冲区（Re-Order Buffer，ROB）的地方。

6. 在重排序缓冲区里，我们的 CPU 会按照取指令的顺序，对指令的计算结果重新排序。只有排在前面的指令都已经完成了，才会提交指令，完成整个指令的运算结果。

7. 实际的指令的计算结果数据，并不是直接写到内存或者高速缓存里，而是先写入存储缓冲区（Store Buffer 面，最终才会写入到高速缓存和内存里。

   可以看到，在乱序执行的情况下，只有 CPU 内部指令的执行层面，可能是“乱序”的。只要我们能在指令的译码阶段正确地分析出指令之间的数据依赖关系，这个“乱序”就只会在互相没有影响的指令之间发生。即便指令的执行过程中是乱序的，我们在最终指令的计算结果写入到寄存器和内存之前，依然会进行一次排序，以确保所有指令在外部看来仍然是有序完成的。

##### 三、控制冒险和解决方案

###### 1、控制冒险

在结构冒险和数据冒险中，你会发现，所有的流水线停顿操作都要从指令执行阶段开始。流水线的前两个阶段，也就是取指令（IF）和指令译码（ID）的阶段，是不需要停顿的。CPU 会在流水线里面直接去取下一条指令，然后进行译码。

取指令和指令译码不会需要遇到任何停顿，这是基于一个假设。这个假设就是，所有的指令代码都是顺序加载执行的。不过这个假设，在执行的代码中，一旦遇到 if…else 这样的条件分支，或者 for/while 循环，就会不成立。这种为了确保能取到正确的指令，而不得不进行等待延迟的情况，就是 **控制冒险（Control Harzard）**。

###### 2、控制冒险解决方案

（1）**缩短分支延迟**，这种方式，本质上和前面数据冒险的操作数前推的解决方案类似，就是在硬件电路层面，把一些计算结果更早地反馈到流水线中。这样反馈变得更快了，后面的指令需要等待的时间就变短了。

（2）**分支预测-静态分支预测**，顾名思义，自然就是仍然按照顺序，把指令往下执行。其实就是 CPU 预测，条件跳转一定不发生。这样的预测方法，其实也是一种静态预测技术。就好像猜硬币的时候，会有 50% 的正确率。

如果分支预测失败了呢？就把后面已经取出指令已经执行的部分，给丢弃掉。这个丢弃的操作，在流水线里面，叫作 Zap 或者 Flush。CPU 不仅要执行后面的指令，对于这些已经在流水线里面执行到一半的指令，还需要做对应的清除操作。比如，清空已经使用的寄存器里面的数据等等，这些清除操作，也有一定的开销。

<img src="https://liuyang-picbed.oss-cn-shanghai.aliyuncs.com/img/39d114b3e37fe7fbad98ef0322b876c3.jpeg" alt="39d114b3e37fe7fbad98ef0322b876c3" style="zoom:25%;" />

（3）**分支预测-动态分支预测**，我们日常生活里，最经常会遇到的预测就是天气预报。如果没有气象台给你天气预报，你想要猜一猜明天是不是下雨，你会怎么办？

有一个简单的策略，就是完全根据今天的天气来猜。如果今天下雨，我们就预测明天下雨。如果今天天晴，就预测明天也不会下雨。这是一个很符合我们日常生活经验的预测。因为一般下雨天，都是连着下几天，不断地间隔地发生“天晴 - 下雨 - 天晴 - 下雨”的情况并不多见。

同样的策略，我们一样可以放在分支预测上。这种策略，我们叫 **一级分支预测（One Level Branch Prediction）**，或者叫  **1 比特饱和计数（1-bit saturating counter）**。这个方法，其实就是用一个比特，去记录当前分支的比较情况，直接用当前分支的比较情况，来预测下一次分支时候的比较情况。





进一步理解流水线冒险里数据冒险的相关知识，可以仔细看一看《计算机组成与设计：硬件 / 软件接口》的第 4.5～4.7 章。

想要更深入地了解 CPU 的乱序执行的知识，就不能局限于组成原理，而要深入到体系结构中去了。可以读一下《计算机体系结构：量化研究方法》的 3.4 和 3.5 章节。